{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmd2pFx-aZ7m"
   },
   "source": [
    "## INFO 371 Problem Set 6\n",
    "\n",
    "*Name*: Xiaobing Xu\n",
    "\n",
    "*Section*: INFO 371 AA\n",
    "\n",
    "*Date*: May 22nd, 2022\n",
    "\n",
    "*Late Day*: Use 1 late day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YXvrIKUMatNb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jz6iSgPc0Fk"
   },
   "source": [
    "#### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tJmMv3L5a-C3",
    "outputId": "376fb4e6-1735-4cfa-ee9e-8338e18567de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5a8d52a6-ac15-4e32-9a39-4d76341b0ecf\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg1.txt</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg2.txt</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg3.txt</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3-375msg1.txt</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg1.txt</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a8d52a6-ac15-4e32-9a39-4d76341b0ecf')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5a8d52a6-ac15-4e32-9a39-4d76341b0ecf button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5a8d52a6-ac15-4e32-9a39-4d76341b0ecf');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    spam          files                                            message\n",
       "0  False    3-1msg1.txt  Subject: re : 2 . 882 s - > np np  > date : su...\n",
       "1  False    3-1msg2.txt  Subject: s - > np + np  the discussion of s - ...\n",
       "2  False    3-1msg3.txt  Subject: 2 . 882 s - > np np  . . . for me it ...\n",
       "3  False  3-375msg1.txt  Subject: gent conference  \" for the listserv \"...\n",
       "4  False  3-378msg1.txt  Subject: query : causatives in korean  could a..."
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv('lingspam-emails .csv.bz2', sep='\\t')\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg1.txt</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg2.txt</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg3.txt</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3-375msg1.txt</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg1.txt</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam          files                                            message\n",
       "0  False    3-1msg1.txt  Subject: re : 2 . 882 s - > np np  > date : su...\n",
       "1  False    3-1msg2.txt  Subject: s - > np + np  the discussion of s - ...\n",
       "2  False    3-1msg3.txt  Subject: 2 . 882 s - > np np  . . . for me it ...\n",
       "3  False  3-375msg1.txt  Subject: gent conference  \" for the listserv \"...\n",
       "4  False  3-378msg1.txt  Subject: query : causatives in korean  could a..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv(\"../Data/all-data/lingspam-emails.csv.bz2\",sep='\\t')\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wphkK_iPczAC"
   },
   "source": [
    "#### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wl_zX5rcb1Xh"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "# define vectorizer\n",
    "X = vectorizer.fit_transform(emails.message)\n",
    "Y = emails.spam.values\n",
    "# vectorize your data. Note: this creates a sparse matrix, # use .toarray() if you run into trouble\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "# in case you want to see what are the actual words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Oed0HEngV5Rg"
   },
   "outputs": [],
   "source": [
    "DTM = pd.DataFrame(X.toarray(), columns=vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu1V2p3-c8U5"
   },
   "source": [
    "#### 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "U9n1UfJtcA3O"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xt, Xv, Yt, Yv = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXPFV1U5c_PP"
   },
   "source": [
    "#### 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnsQGmjpdGJi"
   },
   "source": [
    "- `P_S1`: Pr(category = S)\n",
    "- `P_S0`: Pr(category = NS)\n",
    "- `P_W1`: Pr(word = 1)\n",
    "- `P_W0`: Pr(word = 0)\n",
    "- `P_W1_S1`: Pr(word = 1 | category = S)\n",
    "- `P_W0_S1`: Pr(word = 0 | category = S)\n",
    "- `P_W1_S0`: Pr(word = 1 | category = NS)\n",
    "- `P_W0_S0`: Pr(word = 0 | category = NS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDI7gVRSdC4G"
   },
   "source": [
    "#### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uVQWzrGcgCA",
    "outputId": "71848282-d9d6-4bd3-95c9-5a483c5752ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Subject: efl position in israel  i have been asked to post this job advertisement . please respond to the address in the ad . center for technological education affiliated with tel - aviv university the center for technological education in holon is in the process of establishing an english as a foreign language unit . the unit will provide the required english courses for all students of the center . it will be associated with the faculty of social sciences . we are currently looking to fill the position of head of this unit . the position carries a teaching load of twelve hours per semester as well as responsibility for the academic , professional and organizational aspects of the unit . in addition , scholarly activity and participation in the academic life of the faculty of the social sciences is expected . candidates should have a masters degree in a relevant domain as well as several years of teaching english as a foreign language at one of the universities in israel . scholarly activity , publications and organizational experience are also desirable . the initial appointment will most likely be at the level of ' moreh ' on the parallel academic track . interested candidates should send their cv , list of publications , and other relevant material to the efl search committee , c / o dalia man , center for technological education , p . o . box 305 , holon 58102 , israel . the process of selection will continue until the position is filled .\",\n",
       "       \"Subject: job : english in keio univ ( 2nd posting )  faculty position , keio university keio university 's faculty of science and technology wishes to announce the opening of a full-time position in english and related areas , beginning in april , 1996 . applicants should be native or near-native speakers of japanese , have graduated from a japanese university in english or a closely related field , have completed at least the course work for a doctoral degree in the humanities or social sciences , and have at least three years in research and teaching experience . the successful candidate will be appointed at the rank of tenured assistant professor ( shennin koushi ) . required documents to be submitted : 1 . curriculum vitae , according to the japanese style and format , with one photograph 2 . a list of research papers 3 . three sample publications , one of each , either originals or copies 4 . a description of the candidate 's future research plans ( approximately two a - 4 pages ) 5 . a statement of the candidate 's views regarding university english education ( approximately one a - 4 page ) deadline september 9 , 1995 ( the post cancellation mark will serve as validation . ) selection process candidates who pass the initial screening process will be invited of an interview ( travel and lodging will be at the applicant 's expense ) . direct notification of the date and other details will be subsequently provided . address to which applications and accompanying documents are to be sent : hiyoshi kyoumuka ( rikougakubu ) keio university 4 - 1 - 1 hiyoshi kouhoku - ku , yokohama 223 japan note 1 . applications and accompanying documents should be sent by registered mail , with a notice in red ink , preferably in japanese , noting their contents . 2 . applicants should be aware that the submitted materials cannot be returned . 3 . should you have any questions , please contact professor keiji nakano ( e - mail : a01057 @ cc . hc . keio . ac . jp ) .\",\n",
       "       \"Subject: icslp 96  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = iiii ccccc sssss ll pppppp 999999 666666 ii cc cc ss ss ll pp pp 99 99 66 66 ii cc ss ll pp pp 99 99 66 ii cc sssssss ll pppppp 9999999 6666666 ii cc ss ll pp 99 66 66 ii cc cc ss ss ll pp 99 99 66 66 iiii ccccc sssss lllllll pp 999999 666666 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = fourth international conference on spoken language processing * * * * * * october 3 - 6 , 1996 wyndham franklin plaza hotel philadelphia , pa , usa * * * * * * _ _ _ _ _ _ _ _ _ _ icslp 96 organizers _ _ _ _ _ _ _ _ _ _ _ h . timothy bunnell , chair richard a . foulds , vice - chair applied science & engineering laboratories wilmington , de , usa * * * * * * _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ icslp _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ icslp unites researchers , developers , and clinicians for an exchange on a wide variety of topics related to the spoken language processing of humans and machines . conference presentations range from basic acoustic phonetic research to clinically oriented speech training devices to speech-based natural language interfaces for man-machine interaction . icslp 96 will feature technical sessions of both oral and poster format , plenary talks , commercial exhibits , and daily special sessions . in addition , satellite workshops will be held in conjunction with the conference in the areas of interactive voice technology , spoken dialogue , speech databases and speech i / o , and gestures and speech . a new emphasis for icslp 96 will be on the clinical applications of speech technology , including the use of speech technology based applications for persons with disabilities . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ conference update _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 8 / 10 / 95 dates to note : january 15 , 1996 - paper abstracts due for review march 15 , 1996 - acceptance notification may 1 , 1996 - deadline for papers ( camera-ready , 4 pages ) prospective authors are invited to submit papers relevant to spoken language processing in any of the conference technical areas . abstracts of proposed papers must be received by the icslp 96 organizing committee no later than january 15 , 1996 . papers will be selected by the icslp 96 technical program committee and assigned for presentation in poster or oral format . english is the working language for the conference . submission of an abstract implies a commitment to submit a four page , camera-ready version of the paper and to present the paper in either an oral or poster session if the abstract is accepted . participants will be expected to pay their own registration fees , travel , and accommodations for icslp 96 . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ submission of abstracts _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ abstracts must be received by the icslp 96 organizing committee no later than january 15 , 1996 . abstracts may be submitted either by post or by e-mail following these guidelines : + one page , 400 word maximum + technical area ( s ) indicated in order of preference using the codes ( a - x ) below . + title of the proposed paper clearly indicated + preference for paper or poster clearly indicated + if sent by post , submit four ( 4 ) copies of the abstract + if sent by e-mail , use plain text ( ascii ) format only each abstract must also include the following contact information : + author name ( s ) * + postal mailing address + phone number + fax number + e - mail address e - mailed abstracts will be acknowledged by e-mail within 48 hours of submission . if you do not receive e-mail confirmation , we have not received your abstract ! please check the e-mail address and resubmit . please do not e-mail multiple copies for any other reason . * please be sure that the primary contact person is noted if it is someone other than the first author . mail or send abstracts to : icslp 96 applied science & engineering laboratories a . i . dupont institute p . o . box 269 wilmington , de 19899 e - mail : icslp - abstract @ asel . udel . edu _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ technical areas _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ a . production of spoken language b . perception of spoken language c . robust speech modeling and speech enhancement d . speech coding and transmission e . automatic speech recognition f . spoken language processing for special populations g . phonetics and phonology h . spoken discourse analysis / synthesis i . synthesis of spoken language j . applications for people with speech / language / hearing disorders k . databases and standards for speech technology l . prosody of spoken language m . speech analysis and parameterization n . spoken language acquisition / learning o . integrating spoken language and natural language processing p . hardware for speech processing q . neural networks and stochastic modeling of spoken language r . dialects and speaking styles s . instructional technology for spoken language t . speaker / language identification and verification u . human factors and assessment in spoken language applications v . spoken language dialogue and conversation w . gesture and multimodal spoken language processing x . other _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ satellite workshops _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the following satellite workshops will be held immediately before or after the icslp 96 conference . 1 . ivtta - the 3rd ieee workshop on interactive voice technology for telecommunications applications ( ivtta ) will be held at the at&t learning center , basking ridge , new jersey , from september 30 - october 1 , 1996 . the ivtta workshop brings together applications researchers planning to conduct or who have recently conducted field trials of new applications of speech technologies . due to workshop facility constraints , attendance will be limited primarily to contributors . for further information about the workshop , contact : dr . murray spiegel bellcore 445 south street morristown , nj , usa e-mail : spiegel @ bellcore . com phone : 1-201 - 829-4519 ; fax : 1-201 - 829-5963 submit abstracts ( 400 words , maximum 1 page ) before april 1 , 1996 to : dr . david roe ieee ivtta ` 96 at&t bell laboratories , room 2d-533 murray hill , nj 07974 e-mail : roe @ hogpb . att . com phone : 908 582-2548 ; fax : 908 582-3306 2 . issd-96 the 1996 international symposium on spoken dialogue ( issd-96 ) will be held on october 2 and 3 at the venue of icslp 96 . it is intended to be a forum of interdisciplinary exchange between researchers working on spoken dialogues from various points of view . the first day is devoted to invited lectures followed by sessions of both invited and contributed papers , which will be continued on the second day as special sessions of icslp 96 . papers submitted to icslp 96 ( technical areas h , l , o , u , &v ) may be selected for presentation at the symposium . for further information about the symposium , contact : prof . hiroya fujisaki , chairman , issd-96 dept . of applied electronics science university of tokyo 2641 yamazaki , noda , 278 japan e-mail : fujisaki @ te . noda . sut . ad . jp phone : + 81-471 - 23-4327 ; fax : + 81-471 - 22-9195 3 . cocosda workshop 96 cocosda workshop 96 will be held on monday , october 7 at the wyndham franklin plaza hotel . the international coordinating committee on speech databases and speech i / o systems assessment ( cocosda ) has been established to promote international cooperation in the fundamental areas of spoken language engineering . previous meetings have taken place in banff 1992 , berlin 1993 , yokohama 1994 and madrid 1995 . program and registration information for cocosda 96 will be forthcoming in later announcements . for more information about cocosda , consult the web page at http : / / www . itl . atr . co . jp / cocosda . 4 . workshop on gesture and speech the applied science and engineering laboratories of the university of delaware will host a workshop on multimodal use of gesture and speech october 7 - 8 , 1996 . this workshop will consider the integration of gesture and spoken language in intelligent human / computer interfaces , in advanced assisitve technology for individuals with disabilities , in telemanipulation and robotics systems , and in human conversation . gestures including hand postures , dynamic arm movements , facial expression , and eye gaze will be considered along with more traditional lip shapes and handwriting movements . for further information , contact : dr . lynn messing a . i . dupont institute p . o . box 269 wilmington , de 19899 e-mail : messing @ asel . udel . edu phone : + 1 302 651 6830 ; fax : + 1-302 - 651-6895 _ _ _ _ _ _ _ _ _ _ _ _ _ _ sponsoring and cooperating organizations _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the acoustical society of america american speech and hearing association ( pending ) the acoustical society of japan canadian acoustical association european speech communication association ieee signal processing society international phonetic association others - contact icslp 96 . _ _ _ _ _ _ _ _ _ _ _ _ _ _ for more information , contact _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ icslp 96 applied science & engineering laboratories a . i . dupont institute p . o . box 269 wilmington , de 19899 phone : + 1 302 651 6830 tdd : + 1 302 651 6834 fax : + 1 302 651 6895 email : icslp96 @ asel . udel . edu www : http : / / www . asel . udel . edu / speech / icslp . html ftp : zeppo . asel . udel . edu : pub / icslp a two-page postscript format copy of the most recent conference announcement and call for papers can also be obtained by anonyomus ftp . connect to host zeppo . asel . udel . edu , cd to directory pub / icslp96 , and get call . ps . z in binary mode . the file must be uncompressed with a unix compatable uncompress program before being printed . this plain text version of the announcement is located in the same directory as file call . txt _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ international advisory board _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ hiroya fujisaki science university of tokyo tokyo , japan jens blauert john ohala ruhr - universitat bochum university of california bochum , germany berkeley , ca , usa anne cutler lawrence rabiner max planck institute for at&t bell labs psycholinguistics murray hill , nj , usa nijmegen , the netherlands gunnar fant katsuhiko shirai royal institute of technology ( kth ) waseda university stockholm , sweden tokyo , japan john laver kenneth stevens humanities research board of massachusetts institute the british academy of technology edinburgh , scotland cambridge , ma , usa joseph mariani yoh ' ichi tohkura limsi-cnrs atr human information orsay , france processing research lab kyoto , japan j . bruce millar victor zue australian national university massachusetts institute canberra , australia of technology cambridge , ma , usa _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. emails correstponding to\n",
    "emails.message.values[946:949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWOPgVrieVlw",
    "outputId": "85ddd22d-7c9c-4bf4-f4c9-96e270de7119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interventions', 'intervient', 'interview', 'interviewed', 'interviewing']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. words corresponding to\n",
    "vocabulary[30037:30042]\n",
    "\n",
    "# c. 1 indicates that the corresponding email contains the word\n",
    "\n",
    "# d. 0 indicates that the corresponding email does not contain the word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVKBbm0fe8to"
   },
   "source": [
    "#### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4id6g0ve-76",
    "outputId": "ada713bd-fbe6-4de2-c8cf-5fd508111d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8337366055997235\n"
     ]
    }
   ],
   "source": [
    "spam_count = np.count_nonzero(Y)\n",
    "non_spam_count = np.size(Y) - np.count_nonzero(Y)\n",
    "\n",
    "# majority classfier accuracy\n",
    "if spam_count > non_spam_count:\n",
    "  print(np.mean(Y))\n",
    "else:\n",
    "  print(1 - np.mean(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykm_NLw2iIOo"
   },
   "source": [
    "#### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "KcFzPurViJfp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-bd18f733a0bb>:3: RuntimeWarning: divide by zero encountered in log\n",
      "  lg_P_W1_S1 = np.log(Xt.toarray()[Yt].mean(axis = 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Pr(W=1|S=1) [-1.11175308 -1.15224444 -5.94803499 ...        -inf -5.94803499\n",
      "        -inf]\n",
      "Log Pr(W=1|S=0) [-1.8164003  -2.9808258  -7.56579328 ... -7.56579328        -inf\n",
      " -7.56579328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-bd18f733a0bb>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  lg_P_W1_S0 = np.log(Xt.toarray()[~Yt].mean(axis = 0))\n"
     ]
    }
   ],
   "source": [
    "lg_P_S1 = np.log(np.mean(Yt))\n",
    "lg_P_S0 = np.log(np.mean(~Yt))\n",
    "lg_P_W1_S1 = np.log(Xt.toarray()[Yt].mean(axis = 0)) \n",
    "lg_P_W1_S0 = np.log(Xt.toarray()[~Yt].mean(axis = 0)) \n",
    "print('Log Pr(W=1|S=1)', lg_P_W1_S1)\n",
    "print('Log Pr(W=1|S=0)', lg_P_W1_S0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_sm70Hzr2ai"
   },
   "source": [
    "#### 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "k6uDKSdZz41c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.72848638e+03, -1.89543331e+03, -1.29135429e+01, ...,\n",
       "        -1.46544896e+01, -7.74573479e+00, -4.80224268e+00],\n",
       "       [-5.02513076e+03, -2.52937558e+03, -2.06015324e+01, ...,\n",
       "        -1.46544917e+01, -1.46544917e+01, -1.46544917e+01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_prob(content):\n",
    "    idx = np.where(content == 1)\n",
    "    tmpt_lg_P_S1 = lg_P_S1 + np.sum(lg_P_W1_S1[np.array(idx)])\n",
    "    tmpt_lg_P_S0 = lg_P_S0 + np.sum(lg_P_W1_S0[np.array(idx)])\n",
    "    return [tmpt_lg_P_S0, tmpt_lg_P_S1]\n",
    "result0 = np.apply_along_axis(compute_prob, 0, Xt.toarray())\n",
    "result0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zj36vvbn378X",
    "outputId": "b997fc82-b81c-4460-b3f2-cd98c1b34a19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -119.72887873,  -185.35832011],\n",
       "       [ -156.22747489,  -304.66505131],\n",
       "       [ -688.41425307, -1328.66846632],\n",
       "       ...,\n",
       "       [-2786.76251968, -4803.69918812],\n",
       "       [ -113.45438561,  -171.56366323],\n",
       "       [ -463.91973678,  -895.7980158 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = np.apply_along_axis(compute_prob, 1, Xt.toarray())\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 60925)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2314, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA-xdmoE4qc3"
   },
   "source": [
    "#### 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QMficcy4sy_"
   },
   "source": [
    "We have to compute 2 dimension (probabilities) for each email, because we have to compare these probabilities to classify the email as spam or non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hlwn7apq450v"
   },
   "source": [
    "#### 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WhAyyoPtr4Ug"
   },
   "outputs": [],
   "source": [
    "def predict(content):\n",
    "  idx = np.where(content == 1)\n",
    "  tmpt_lg_P_S1 = lg_P_S1 + np.sum(lg_P_W1_S1[np.array(idx)])\n",
    "  tmpt_lg_P_S0 = lg_P_S0 + np.sum(lg_P_W1_S0[np.array(idx)])\n",
    "  if tmpt_lg_P_S1 > tmpt_lg_P_S0:\n",
    "    return True\n",
    "  else:\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sS5Eb-EBuq1u",
    "outputId": "814da504-1945-4393-bdac-a880bfd057e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = np.apply_along_axis(predict, 1, Xv.toarray())\n",
    "Y_predict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have need higher the value of the log-likelihood(579), which results in a better model fitting a dataset, and it is useful for comparing two or more models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.72848638e+03, -1.89543331e+03, -1.29135429e+01, ...,\n",
       "        -1.46544896e+01, -7.74573479e+00, -4.80224268e+00],\n",
       "       [-5.02513076e+03, -2.52937558e+03, -2.06015324e+01, ...,\n",
       "        -1.46544917e+01, -1.46544917e+01, -1.46544917e+01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(content):\n",
    "    idx = np.where(content == 1)\n",
    "    tmpt_lg_P_S1 = lg_P_S1 + np.sum(lg_P_W1_S1[np.array(idx)])\n",
    "    tmpt_lg_P_S0 = lg_P_S0 + np.sum(lg_P_W1_S0[np.array(idx)])\n",
    "    return [tmpt_lg_P_S0, tmpt_lg_P_S1]\n",
    "S0 = np.apply_along_axis(predict, 0, Xt.toarray())\n",
    "S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -119.72887873,  -185.35832011],\n",
       "       [ -156.22747489,  -304.66505131],\n",
       "       [ -688.41425307, -1328.66846632],\n",
       "       ...,\n",
       "       [-2786.76251968, -4803.69918812],\n",
       "       [ -113.45438561,  -171.56366323],\n",
       "       [ -463.91973678,  -895.7980158 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1 = np.apply_along_axis(predict, 1, Xt.toarray())\n",
    "S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MVaOK_t5C13"
   },
   "source": [
    "#### 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iwflr3Fm5CE9",
    "outputId": "58838618-4883-4c11-a5cf-0ce315c93524"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[483,   0],\n",
       "       [ 82,  14]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Yv, Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TnkZ6-2D5dyH",
    "outputId": "b8f41425-3552-4abb-a9a3-b95b9a7dc583"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583765112262521"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(Yv, Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjMFmZ2K5yRN",
    "outputId": "3fce923a-ecac-4bca-d693-20d41c7bce74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8341968911917098"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.mean(Yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cause of such a problem of many infinities was the 0 probability of count of word with regards to few cases of the word, relying on a single rare value for categorization. Thus, we need smoothing methodadding a\n",
    "small positive number to the counts to caculate probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfHfZTux7TSC"
   },
   "source": [
    "#### 3.1 & 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YE-3zStb7SY8"
   },
   "outputs": [],
   "source": [
    "def fitting(Xt, Yt, alpha):\n",
    "  n_spam = np.sum(Yt) + alpha\n",
    "  n_non_spam = np.sum(~Yt) + alpha\n",
    "  n_total = n_spam + n_non_spam\n",
    "  spam_counts = Xt.toarray()[Yt].sum(0) + alpha\n",
    "  non_spam_counts = Xt.toarray()[~Yt].sum(0) + alpha\n",
    "  lg_P_S1 = np.log(n_spam / n_total) \n",
    "  lg_P_S0 = np.log(n_non_spam / n_total) \n",
    "  lg_P_W1_S1 = np.log(spam_counts / (n_spam + alpha)) \n",
    "  lg_P_W1_S0 = np.log(non_spam_counts / (n_non_spam + alpha))\n",
    "\n",
    "  return lg_P_S1, lg_P_S0, lg_P_W1_S1, lg_P_W1_S0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q5l4Rc9yg93"
   },
   "source": [
    "#### 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVL9brWCPiWJ",
    "outputId": "6888981c-ba6a-470f-9c45-7fe8bea32a7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-18bc80bcd65d>:9: RuntimeWarning: divide by zero encountered in log\n",
      "  lg_P_W1_S1 = np.log(spam_counts / (n_spam + alpha))\n",
      "<ipython-input-22-18bc80bcd65d>:10: RuntimeWarning: divide by zero encountered in log\n",
      "  lg_P_W1_S0 = np.log(non_spam_counts / (n_non_spam + alpha))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0\n",
      "Confusion Matrix:\n",
      " [[481   0]\n",
      " [ 87  11]]\n",
      "Accuracy: 0.8497409326424871\n",
      "Alpha: 0.1\n",
      "Confusion Matrix:\n",
      " [[474   7]\n",
      " [  0  98]]\n",
      "Accuracy: 0.9879101899827288\n",
      "Alpha: 0.2\n",
      "Confusion Matrix:\n",
      " [[470  11]\n",
      " [  0  98]]\n",
      "Accuracy: 0.9810017271157168\n",
      "Alpha: 0.3\n",
      "Confusion Matrix:\n",
      " [[467  14]\n",
      " [  0  98]]\n",
      "Accuracy: 0.9758203799654577\n",
      "Alpha: 0.4\n",
      "Confusion Matrix:\n",
      " [[462  19]\n",
      " [  0  98]]\n",
      "Accuracy: 0.9671848013816926\n"
     ]
    }
   ],
   "source": [
    "for alpha in range(5):\n",
    "  lg_P_S1, lg_P_S0, lg_P_W1_S1, lg_P_W1_S0 = fitting(Xt, Yt, alpha / 10)\n",
    "  Y_predict = np.apply_along_axis(predict, 1, Xv.toarray())\n",
    "  print('Alpha:', alpha / 10)\n",
    "  print('Confusion Matrix:\\n', confusion_matrix(Yv, Y_predict))\n",
    "  print('Accuracy:', accuracy_score(Yv, Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aErxpazyjGn"
   },
   "source": [
    "#### 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCVlmjJiU_Ba",
    "outputId": "7edc512d-18ff-4363-fdd4-19e5bb29e2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1e-08\n",
      "Confusion Matrix:\n",
      " [[486   0]\n",
      " [ 11  82]]\n",
      "Accuracy: 0.9810017271157168\n",
      "Alpha: 1e-07\n",
      "Confusion Matrix:\n",
      " [[486   0]\n",
      " [ 11  82]]\n",
      "Accuracy: 0.9810017271157168\n",
      "Alpha: 1e-06\n",
      "Confusion Matrix:\n",
      " [[486   0]\n",
      " [  8  85]]\n",
      "Accuracy: 0.9861830742659758\n",
      "Alpha: 1e-05\n",
      "Confusion Matrix:\n",
      " [[486   0]\n",
      " [  7  86]]\n",
      "Accuracy: 0.9879101899827288\n",
      "Alpha: 0.0001\n",
      "Confusion Matrix:\n",
      " [[486   0]\n",
      " [  7  86]]\n",
      "Accuracy: 0.9879101899827288\n",
      "Alpha: 0.001\n",
      "Confusion Matrix:\n",
      " [[486   0]\n",
      " [  4  89]]\n",
      "Accuracy: 0.9930915371329879\n",
      "Alpha: 0.01\n",
      "Confusion Matrix:\n",
      " [[486   0]\n",
      " [  3  90]]\n",
      "Accuracy: 0.9948186528497409\n",
      "Alpha: 0.1\n",
      "Confusion Matrix:\n",
      " [[481   5]\n",
      " [  1  92]]\n",
      "Accuracy: 0.9896373056994818\n",
      "Alpha: 1.0\n",
      "Confusion Matrix:\n",
      " [[436  50]\n",
      " [  0  93]]\n",
      "Accuracy: 0.9136442141623489\n",
      "Alpha: 10.0\n",
      "Confusion Matrix:\n",
      " [[ 58 428]\n",
      " [  0  93]]\n",
      "Accuracy: 0.2607944732297064\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-8, 1, num=10)\n",
    "accuracies = []\n",
    "for i in alphas:\n",
    "  lg_P_S1, lg_P_S0, lg_P_W1_S1, lg_P_W1_S0 = fitting(Xt, Yt, i)\n",
    "  Y_predict = np.apply_along_axis(predict, 1, Xv.toarray())\n",
    "  accuracies.append(accuracy_score(Yv, Y_predict))\n",
    "  print('Alpha:', i)\n",
    "  print('Confusion Matrix:\\n', confusion_matrix(Yv, Y_predict))\n",
    "  print('Accuracy:', accuracy_score(Yv, Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYEoVai8yp54"
   },
   "source": [
    "According to the accuracies above, the model performs best with an alpha of 0.001. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOMB_zZMyZ9R"
   },
   "source": [
    "#### 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "bU3OWEENm3oY",
    "outputId": "50aac43e-07fd-45c1-89b2-fd482d3f61f3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcJ0lEQVR4nO3de3Scd33n8fdHI8mWLyMTSzge2cEmOMEahSbUGAqnOBBonLLrpHBON+npboGWNF1c7oFkW7I0vUAJLV2WlG66ZLkskGbZbDBgMJdAyi00CrngS5wohhDLdqLE8d3xWJrv/qGRPZIla2TNzDMz+rzOmaN5nvlpnq/H0md++v3m+T2KCMzMrP41JV2AmZmVhwPdzKxBONDNzBqEA93MrEE40M3MGkRzUgfu6OiIZcuWJXV4M7O6dN999z0dEZ3jPZZYoC9btoze3t6kDm9mVpckPT7RYx5yMTNrEA50M7MG4UA3M2sQDnQzswYxaaBLulXSU5I2T/C4JH1CUp+khyS9tPxlmpnZZEr5lMtngE8Cn5vg8cuAFYXby4FPFb6aWULuvL+fmzZtZ9e+o2QWtHHtpedzxUVdSZdlFTZpoEfEv0padpomlwOfi+FlG++RtEDS4ojYXaYazepGLQTpnff3c/0dP+fo8SEA+vcd5fo7fg7gUG9w5fgcehfwRNH2zsK+UwJd0tXA1QDnnHNOGQ5ttaAWQqwW6hgvSK+74yEOPHecS7NnM5gP8vlgMB8Mjb1FMJTPM5SHwXyefOHrqW2Gb8XPlY9gcKjwNR/84/f6TtQw4ujxIT701S20pJpoa22iraWZttYUc1pTtLWkTtyf3ZyiqUllfU1q4WdjplAp66EXeuhfi4iecR77GvCRiPhhYfu7wAci4rRnDa1atSp8YtH01MIvy9gQA2hrSfHhN16QaJiero7jQ3mOHh/iaG74diQ3dGL7SG7w5GPHC48V3X/u+HCbk/dPfu+eA8/RCJcXmN3SRFtLijmtw6E/EvjD+0a/AQzfb6atpYk5rc3Mbk0xp9Du3365l099/zGODeZPPHcSPxuNRtJ9EbFq3MfKEOj/A/h+RHypsL0duHiyIZczCfRaCLCk68jng+cGh7jjZzv5y69tG/XLMqu5iT9e80JeeW7HyZ5gBENDJ3t3o3p2o9rkGQpO9BJHfY3xvy8fwVce2MWR3NApdba1pPit7KKqvCYA39ry5Cm9UoDmJrH0rDnDQV0I3+NDU0tdCeaMBFdrE3NamkcF3EiI/Z/7dk74HH/zOxeQaoJUU9PJrxKppuFbc5NoGvkq0ZwqfG06fZvi5xi5ve7v7mbX/udOqWFRehaf/8OXF71JDY56wxp5cxt5oyp+Axv7Jlf8ZjbVN7GuBW386LrXTu2b7ITTBXo5hlw2AOsl3cbwZOj+Soyf18q44GR1DOWj8EM/OPoXYExP8GTvb/Dk/Yl+aU7sG+S54/kJazs2mOcT3+3jE9/tK+u/uThIUhKpoiAZL8xh+E/8B5/YV9Y6Tme8MAcYzAc9Xe2FQC70LIvun+h1tjafDOgxPdFZzU1Ikw9D/PixZ+jfd/SU/V0L2vi9l1dviPH9a1887l8r11+2kvMWzS/rsSKCY4P5op/fQY7m8hzJDfIfbrln3O/ZNc5rZOUxaQ9d0peAi4EO4EngvwItABHxTxr+Sf8ksBY4ArxlsuEWmHoP/VUfuWvcX5aWlOjOtJf8PNO1ddf+cXt4ErSkmsgNThy4EzklSEYFTaow3ln4k7aw/yPfeHjC5/viH738lF7bqF6eRHNTE01N0NzUdJo2mnQ8daL/l2r3wmqhjloZfhqpJem/Zif6PwG4Zs25vOOSFzGnNbHlpOrWtHroEXHVJI8H8PYzrK1kE72rHx8KFrS1VPrwo443ngh4y6uWMaeledSf4af0BE+MPw73CGe3lNb7G+vzP3l8wgB75Ys6pvx8Z+raS88fN8SuvfT8qtVQK3WMBGbSQTpSS9Lj1OP9n8xuaeIlXe38092PseGBfm74991cmj37jH4H7FR18/aYWdA2YYB99q2rq1bH6XqC11+2smp11EKAQe2EWC3VkXSQ1orT/Z/c+8u9fPDOzVzzv3/GmvM6+Yt1WZZ1zE244vpX0qRoJUx1yKVW/pytlTpGakk6wMzO1OBQns/+5HE+/u1HyA3luWbNufzni89ldksq6dJq2rQ/5VIJ/pSLmQE8eeA5/vrr29jw4C6WntXGX6zL8toXV+8TUvWmYQLdzBrXj/ue5oNf2cxjA4d5ffcibvh33Sw9a07SZdWc0wW6V1s0s5rwyhd18I13vpoPrH0xP3z0aV7/8bv55F2Pcmxw/I+k2qkc6GZWM1qbm/iTi8/lO+9dw2vOfz4f+9YjXPYPP+AHjw4kXVpdcKCbWc3pWtDGp37/1/nMW15GPoL/+Ol/4+1f+Bm79/ukpNNxoJtZzbr4/OfzzXe9mve8/jy+s+1JLvm7u7nlXx/j+NDUT+CbCRzoZlbTZrekeMclK/j2u9fwGy9cyN9sfJg3fOIH3LPjmaRLqzkOdDOrC+csnMOn3/wy/vk/reLwsSGuvOUe3v0vD/DUwVMXIpupHOhmVlde372I77xnDetf8yK+/tBuLvnY3XzmR79g0MMwDnQzqz9trSned+n5fPNdv8mF5yzgQ1/dyrpP/oj7Hn826dIS5UA3s7r1ws55fO6tq7n5917K3sM53vSpH/P+Lz/I3sO5pEtLhAPdzOqaJN7wksV8571ruPrVL+SOn/Xzmo99ny/89HHy+Qa4hNQU+NR/M2sojzx5kA/euZmf/mIvv7aknb+64gIeGzjUMOsveS0XM5tRonB5xL/6+jaePnSMVJMYKuqt1/O1Tb2Wi5nNKJK44qIu7nrfGubOSo0Kcxi+ZOFNm7YnVF3lONDNrGGlZ7dw5Nj4i3s14rVNSwp0SWslbZfUJ+m6cR5/gaTvSnpI0vclLSl/qWZmU5dZ0Dal/fVs0kCXlAJuBi4DuoGrJHWPafYx4HMR8RLgRuDD5S7UzOxMXHvp+bSNuQpSEpdrrIZSeuirgb6I2BEROeA24PIxbbqBuwr3vzfO42Zmibjioi4+/MYLWDi3FYCOea11OyE6mVICvQt4omh7Z2FfsQeBNxbu/w4wX9LCsU8k6WpJvZJ6Bwa8vrGZVccVF3Wx6d2vBuCaNec2ZJhD+SZF3weskXQ/sAboB06ZiYiIWyJiVUSs6uzsLNOhzcwm1zFvFmenZ7O5f3/SpVRMcwlt+oGlRdtLCvtOiIhdFHrokuYBb4qIfeUq0sysHLKZNFt2HUi6jIoppYd+L7BC0nJJrcCVwIbiBpI6JI081/XAreUt08xs+rKZNI8NHOJorjGvUzppoEfEILAe2ARsA26PiC2SbpS0rtDsYmC7pEeARcBfV6heM7Mz1p1pJx/w8J7G7KWXMuRCRGwENo7Zd0PR/S8DXy5vaWZm5dXTlQZg864DXHTO8xKupvx8pqiZzRhdC9pob2th667GnBh1oJvZjCGpoSdGHehmNqNkM2ke3nOQ4w14yToHupnNKD1d7eQG8/Q9dSjpUsrOgW5mM0o2Mzwx2ojDLg50M5tRlnfMo60lxZYGnBh1oJvZjJJqEi9ePN89dDOzRtCTaWfrrgMNdxFpB7qZzTjZTJpDxwb51d4jSZdSVg50M5txspl2oPEmRh3oZjbjnHf2PJqb1HATow50M5txZjWnWLFoPpvdQzczq3/ZTJqtu/YT0TgTow50M5uRspk0Tx/K8dTBY0mXUjYOdDObkU5OjDbOOLoD3cxmpO7CEgCb+xtnHN2BbmYz0rxZzSzvmOseuplZI+husLXRSwp0SWslbZfUJ+m6cR4/R9L3JN0v6SFJv13+Us3MyiubSbPz2aPsP3I86VLKYtJAl5QCbgYuA7qBqyR1j2n25wxfPPoi4ErgH8tdqJlZufWMTIzuboxhl1J66KuBvojYERE54Dbg8jFtAkgX7rcDu8pXoplZZZxYG71BJkZLCfQu4Imi7Z2FfcU+BPy+pJ3ARuBPx3siSVdL6pXUOzAwcAblmpmVz8J5szg7PbthJkbLNSl6FfCZiFgC/DbweUmnPHdE3BIRqyJiVWdnZ5kObWZ25hrpotGlBHo/sLRoe0lhX7E/BG4HiIifALOBjnIUaGZWSdmudh4bOMTR3FDSpUxbKYF+L7BC0nJJrQxPem4Y0+ZXwCUAklYyHOgeUzGzmpfNpMkHbNtT/730SQM9IgaB9cAmYBvDn2bZIulGSesKzd4LvE3Sg8CXgDdHI614Y2YNq5EuGt1cSqOI2MjwZGfxvhuK7m8FXlXe0szMKq9rQRvtbS1sbYCJUZ8pamYzmiR6uhpjYtSBbmYzXjbTzsO7D3J8KJ90KdPiQDezGS+bSZMbytP31KGkS5kWB7qZzXiNMjHqQDezGW95xzzaWlJ1f8aoA93MZrxUk1i5eH7dr+niQDczY3hidOvuA+Tz9XsKjQPdzIzhcfRDxwb51d4jSZdyxhzoZmZAT9fIRaPrd9jFgW5mBqxYNI/mJrG5jidGHehmZsCs5hQrFs13D93MrBFkM2m27tpPva4t6EA3MyvoyaR5+lCOpw4eS7qUM+JANzMryBYmRjf31+c4ugPdzKxg5eI0Uv1+0sWBbmZWMG9WM8sWzq3bJQAc6GZmRbrr+KLRJQW6pLWStkvqk3TdOI9/XNIDhdsjkvaVv1Qzs8rrybSz89mj7DuSS7qUKZs00CWlgJuBy4Bu4CpJ3cVtIuLdEXFhRFwI/HfgjkoUa2ZWaSNL6W6tw156KT301UBfROyIiBxwG3D5adpfxfCFos3M6k49r41eSqB3AU8Ube8s7DuFpBcAy4G7pl+amVn1LZw3i7PTs+tyYrTck6JXAl+OiKHxHpR0taReSb0DAwNlPrSZWXn0dKXZ3KA99H5gadH2ksK+8VzJaYZbIuKWiFgVEas6OztLr9LMrIq6M+3sGDjE0dy4fdOaVUqg3wuskLRcUivDob1hbCNJLwaeB/ykvCWamVVXNpMmH7BtT3310icN9IgYBNYDm4BtwO0RsUXSjZLWFTW9Ergt6nVVGzOzgnqdGG0upVFEbAQ2jtl3w5jtD5WvLDOz5HQtaGPBnBa21NmaLj5T1MxsDElk6/CMUQe6mdk4spl2tu85yPGhfNKllMyBbmY2jmwmTW4oT99Th5IupWQOdDOzcWQz9bc2ugPdzGwcyzvm0taSqqtxdAe6mdk4Uk1i5eL5dbVIlwPdzGwC2Uw7W3cfIJ+vj9NrHOhmZhPo6Upz6Nggv9p7JOlSSuJANzObwImJ0TpZedGBbmY2gRWL5tHcpLqZGHWgm5lNYFZzihWL5jvQzcwaQU8mzZb+/dTDuoMOdDOz08hm0jxzOMeTB44lXcqkHOhmZqeR7RqeGK2HS9I50M3MTmPl4jRSfayN7kA3MzuNebOaWb5wrnvoZmaNoDuTZnO/e+hmZnUvm2mnf99R9h3JJV3KaZUU6JLWStouqU/SdRO0+V1JWyVtkfTF8pZpZpackWuM1vpCXZMGuqQUcDNwGdANXCWpe0ybFcD1wKsiIgu8qwK1mpklol4uGl1KD3010BcROyIiB9wGXD6mzduAmyPiWYCIeKq8ZZqZJWfhvFksbp9d82u6lBLoXcATRds7C/uKnQecJ+lHku6RtLZcBZqZ1YJ6uGh0uSZFm4EVwMXAVcA/S1owtpGkqyX1SuodGBgo06HNzCqvO9POjoFDHM0NJV3KhEoJ9H5gadH2ksK+YjuBDRFxPCJ+ATzCcMCPEhG3RMSqiFjV2dl5pjWbmVVdTyZNPmDbntrtpZcS6PcCKyQtl9QKXAlsGNPmToZ750jqYHgIZkcZ6zQzS9SJJQBq+KLRkwZ6RAwC64FNwDbg9ojYIulGSesKzTYBz0jaCnwPuDYinqlU0WZm1ZZpn82COS01PY7eXEqjiNgIbByz74ai+wG8p3AzM2s4kmp+YtRnipqZlagn0872PQc5PpRPupRxOdDNzErUnUmTG8rz6JOHki5lXA50M7MSjVw0ulZXXnSgm5mVaHnHXNpaUjU7ju5ANzMrUapJdGfSNbtIlwPdzGwKhj/psp98vvYuGu1ANzObgmwmzeHcEI/vPZJ0KadwoJuZTUEtT4w60M3MpmDFonm0pFSTE6MOdDOzKZjVnGLF8+ezuQbXdHGgm5lNUbbwSZfhVU9qhwPdzGyKspk0zxzO8eSBY0mXMooD3cxsinq6anNi1IFuZjZFKxenkWBzf21NjDrQzcymaO6sZpYvnOseuplZI+iuwbXRHehmZmegp6ud/n1H2Xckl3QpJzjQzczOQDaTBqiphbpKCnRJayVtl9Qn6bpxHn+zpAFJDxRuf1T+Us3MasfIEgCba2gcfdJrikpKATcDrwd2AvdK2hARW8c0/ZeIWF+BGs3Mas5Zc1tZ3D67psbRS+mhrwb6ImJHROSA24DLK1uWmVntq7WLRpcS6F3AE0XbOwv7xnqTpIckfVnS0vGeSNLVknol9Q4MDJxBuWZmtSObaWfHwCGO5AaTLgUo36ToV4FlEfES4NvAZ8drFBG3RMSqiFjV2dlZpkObmSUjm0mTD9i2+2DSpQClBXo/UNzjXlLYd0JEPBMRI4sa/E/g18tTnplZ7coWlgDYWiMTo6UE+r3ACknLJbUCVwIbihtIWly0uQ7YVr4SzcxqU6Z9NgvmtNTMOPqkn3KJiEFJ64FNQAq4NSK2SLoR6I2IDcA7JK0DBoG9wJsrWLOZWU2QRE+mvX4CHSAiNgIbx+y7oej+9cD15S3NzKz2ZTNp/tePfsnxoTwtqWTP1fSZomZm09CdSZMbyvPok4eSLsWBbmY2HbV00WgHupnZNCzvmMuc1lRNjKM70M3MpiHVJFYuTruHbmbWCEYuGp3PJ3vRaAe6mdk0ZTNpDueGeHzvkUTrcKCbmU1TrUyMOtDNzKbpvEXzaUkp8YtGO9DNzKaptbmJFc+f7x66mVkjGJkYjUhuYtSBbmZWBj1d7TxzOMeTB45N3rhCHOhmZmUwctHozf3JDbs40M3MymDl4jQSiZ4x6kA3MyuDubOaWb5wbqITow50M7MyyXYluza6A93MrEyymTT9+47y7OFcIsd3oJuZlcnIxOjW3cn00h3oZmZlkvQSACUFuqS1krZL6pN03WnavUlSSFpVvhLNzOrDWXNbybTPTmwcfdJAl5QCbgYuA7qBqyR1j9NuPvBO4KflLtLMrF50Z9oT+yx6KT301UBfROyIiBxwG3D5OO3+Evhb4Lky1mdmVleymTQ7nj7Mkdxg1Y9dSqB3AU8Ube8s7DtB0kuBpRHx9dM9kaSrJfVK6h0YGJhysWZmtS6bSRMB23YfrPqxpz0pKqkJ+HvgvZO1jYhbImJVRKzq7Oyc7qHNzGpOT9fwxOjWBCZGSwn0fmBp0faSwr4R84Ee4PuSfgm8AtjgiVEzm4kWt8/meXNaElkbvZRAvxdYIWm5pFbgSmDDyIMRsT8iOiJiWUQsA+4B1kVEb0UqNjOrYZLIZtrZsrsGe+gRMQisBzYB24DbI2KLpBslrat0gWZm9SabSfPInkMcH8pX9bjNpTSKiI3AxjH7bpig7cXTL8vMrH5lu9rJDeV59MlDdBfOHq0GnylqZlZmJ9ZGr/LEqAPdzKzMli+cy5zWFFurfMaoA93MrMyamsTKxemqr+niQDczq4CewkWj8/nqXTTagW5mVgHZTDuHc0M8vvdI1Y7pQDczq4DuBC4a7UA3M6uA8xbNpyWlqi6l60A3M6uA1uYmzls0v6oTow50M7MKyRYmRiOqMzHqQDczq5Bspp1nDufYc6A6l4lwoJuZVcjIGaNbqrTyogPdzKxCVi5OI1G1iVEHuplZhcyd1czyjrlVmxh1oJuZVVA20+4euplZI8hm0vTvO8qzh3MVP5YD3cysgnoyhWuM7q58L92BbmZWQSc+6VKFcXQHuplZBT1vbiuZ9tlVuWh0SYEuaa2k7ZL6JF03zuPXSPq5pAck/VBSd/lLNTOrT92Z9trooUtKATcDlwHdwFXjBPYXI+KCiLgQ+Cjw92Wv1MysTvV0pdnx9GGO5AYrepxSeuirgb6I2BEROeA24PLiBhFR/LfEXKB6K7qbmdW4bKadCNi2+2BFj1NKoHcBTxRt7yzsG0XS2yU9xnAP/R3jPZGkqyX1SuodGBg4k3rNzOpOtSZGyzYpGhE3R8S5wAeAP5+gzS0RsSoiVnV2dpbr0GZmNW1x+2yeN6el4mu6lBLo/cDSou0lhX0TuQ24YjpFmZk1EknDZ4zuTr6Hfi+wQtJySa3AlcCG4gaSVhRtvgF4tHwlmpnVv2xXmkf2HCI3mK/YMZonaxARg5LWA5uAFHBrRGyRdCPQGxEbgPWSXgccB54F/qBiFZuZ1aFspp3cUJ5HnzpItnD2aLlNGugAEbER2Dhm3w1F999Z5rrMzBrKyYnRAxULdJ8pamZWBcsXzmVOa4qtFVx50YFuZlYFTU2ie3G6oh9ddKCbmVVJW0sTvb98luXXfZ1XfeQu7rz/dB8YnLqSxtDNzGx67ry/n3t+sffEafT9+45y/R0/B+CKi045V/OMuIduZlYFN23azvGh0auiHD0+xE2btpftGA50M7Mq2LXv6JT2nwkHuplZFWQWtE1p/5lwoJuZVcG1l55PW0tq1L62lhTXXnp+2Y7hSVEzsyoYmfi8adN2du07SmZBG9deen7ZJkTBgW5mVjVXXNRV1gAfy0MuZmYNwoFuZtYgHOhmZg3CgW5m1iAc6GZmDUIRMXmrShxYGgAeP8Nv7wCeLmM59c6vx2h+PU7yazFaI7weL4iIcS/KnFigT4ek3ohYlXQdtcKvx2h+PU7yazFao78eHnIxM2sQDnQzswZRr4F+S9IF1Bi/HqP59TjJr8VoDf161OUYupmZnapee+hmZjaGA93MrEHUbaBLulDSPZIekNQraXXSNSVN0p9KeljSFkkfTbqepEl6r6SQ1JF0LUmSdFPh5+IhSf9P0oKka6o2SWslbZfUJ+m6pOuplLoNdOCjwF9ExIXADYXtGUvSa4DLgV+LiCzwsYRLSpSkpcBvAb9KupYa8G2gJyJeAjwCXJ9wPVUlKQXcDFwGdANXSepOtqrKqOdADyBduN8O7EqwllrwJ8BHIuIYQEQ8lXA9Sfs48H5gxs/6R8S3ImKwsHkPsCTJehKwGuiLiB0RkQNuY7jz03DqOdDfBdwk6QmGe6MzqtcxjvOA35T0U0l3S3pZ0gUlRdLlQH9EPJh0LTXorcA3ki6iyrqAJ4q2dxb2NZyavmKRpO8AZ4/z0J8BlwDvjoj/K+l3gU8Dr6tmfdU2yevRDJwFvAJ4GXC7pBdGg34udZLX4r8wPNwyY5zu9YiIrxTa/BkwCHyhmrVZ9dTt59Al7QcWRERIErA/ItKTfV+jkvRN4G8j4nuF7ceAV0TEQLKVVZekC4DvAkcKu5YwPBy3OiL2JFZYwiS9Gfhj4JKIODJJ84Yi6TeAD0XEpYXt6wEi4sOJFlYB9TzksgtYU7j/WuDRBGupBXcCrwGQdB7QSv2vKjdlEfHziHh+RCyLiGUM/3n90hke5msZnk9YN9PCvOBeYIWk5ZJagSuBDQnXVBE1PeQyibcB/01SM/AccHXC9STtVuBWSZuBHPAHjTrcYlP2SWAW8O3hP2a5JyKuSbak6omIQUnrgU1ACrg1IrYkXFZF1O2Qi5mZjVbPQy5mZlbEgW5m1iAc6GZmDcKBbmbWIBzoZmYNwoFuZtYgHOhmZg3i/wODL/fk16lkowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.plot(np.log10(alphas), accuracies, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrN8Mzz4y3AL"
   },
   "source": [
    "#### 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a word's Pr(category = S | word = 1) is large and Pr(category = NS | word = 1) is small, it means that the word belongs to spam category given a word. Meanwhile, when log-likihood is higher, it means that the better a model fits a dataset. Thus, when logPr(category = S | word = 1)-logPr(category = NS | word = 1) is large, it means that the logPr(category = S | word = 1) is large, resulting a better model with higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-E3pRkCfzP-P",
    "outputId": "85133bc5-baf4-405a-bd08-033f31d680fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['linguistic', 'theory', 'syntax', 'deadline', 'abstract',\n",
       "        'abstracts', 'committee', 'structure', 'grammar', 'workshop'],\n",
       "       dtype=object),\n",
       " array(['subject', 'you', 'and', 'to', 'the', 'your', 'for', 'of', 'is',\n",
       "        'this'], dtype=object))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities with best accuracy\n",
    "lg_P_S1, lg_P_S0, lg_P_W1_S1, lg_P_W1_S0 = fitting(Xt, Yt, 0.001)\n",
    "lg_P_W1 = np.log((np.sum(Xt) + 0.001) / (Xt.shape[0] + 0.002))\n",
    "lg_P_S1_W1 = lg_P_W1_S1 * lg_P_S1 / lg_P_W1\n",
    "lg_P_S0_W1 = lg_P_W1_S0 * lg_P_S0 / lg_P_W1\n",
    "lg_diffs = lg_P_S1_W1 - lg_P_S0_W1\n",
    "best_idx = np.argsort(-lg_diffs)[:10]\n",
    "worst_idx = np.argsort(lg_diffs)[:10]\n",
    "best_vocab = vocabulary[best_idx]\n",
    "worst_vocab = vocabulary[worst_idx]\n",
    "(best_vocab, worst_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result especially for least likely spam words (worst_vocab) makes sense to me. This is because those are common conjunction and words which nearly exist in every sentences and cannot predict spam email since its high frequency. The best 10 words to predict spam words are interesting to me."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "info-371-ps-06",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
