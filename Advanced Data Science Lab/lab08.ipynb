{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfbc23b5-d96d-4515-b3d4-5715ecd03397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59b6d05f-008c-4790-80a4-cbd045f6541e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/wuming/Desktop/22 SP/Info 371/Labs'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1398109c-a361-4d6d-a3c0-59222cf8a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in '/Users/wuming/Desktop/22 SP/Info 371/Labs': ['lab04.html', 'lab03.ipynb', 'lab00-test-r-rmd.rmd', '.DS_Store', 'lab07.ipynb', 'lab05.ipynb', 'lab07-nnets.pdf', 'lab05.html', 'lab06-trees.pdf', 'lab02.Rmd', 'lab02.html', 'Lab01.Rmd', 'lab01-ba-cs.pdf', 'lab08-squares-circles.py', 'lab03.html', 'lab04.ipynb', 'Lab Demo', 'lab01-ba-cs.Rmd', 'lab06.ipynb', 'squares-circles', 'lab08-image-recognition.pdf', 'squares-circles.zip', 'lab03-knn.pdf', 'lab08.ipynb', 'lab00-test-python-notebooks.html', 'lab00-test-r-rmd.html', 'lab02-did.pdf', '.ipynb_checkpoints', 'lab06.html', 'lab05-bayes-predict.pdf', 'lab04-pca.pdf', 'lab01-ba-cs.html', 'lab00-test-python-notebooks.ipynb', 'lab07.html']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3124c916-91b7-496d-a4f0-2beb126ec2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define image properties:\n",
    "imgDir = \"squares-circles\"\n",
    "targetWidth, targetHeight = 35, 35\n",
    "imageSize = (targetWidth, targetHeight)\n",
    "channels = 1  # color channels black/white\n",
    "## define other constants, including command line argument defaults\n",
    "epochs = 10\n",
    "plot = False # show plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "348ebd89-3748-4fd2-a5f8-12916972f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run interactively from /Users/wuming/Desktop/22 SP/Info 371/Labs\n",
      "Load images from squares-circles\n",
      "epochs: 10\n"
     ]
    }
   ],
   "source": [
    "## command line arguments\n",
    "# check if this was run as a separate file (not inside notebook)\n",
    "import __main__ as main\n",
    "if hasattr(main, \"__file__\"):\n",
    "    # run as file\n",
    "    print(\"parsing command line arguments\")\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dir\", \"-d\",\n",
    "                        help = \"directory to read images from\",\n",
    "                        default = imgDir)\n",
    "    parser.add_argument(\"--epochs\", \"-e\",\n",
    "                        help = \"how many epochs\",\n",
    "                        default= epochs)\n",
    "    parser.add_argument(\"--plot\", \"-p\",\n",
    "                        action = \"store_true\",\n",
    "                        help = \"plot a few wrong/correct results\")\n",
    "    args = parser.parse_args()\n",
    "    imgDir = args.dir\n",
    "    epochs = int(args.epochs)\n",
    "    plot = args.plot\n",
    "else:\n",
    "    # run as notebook\n",
    "    print(\"run interactively from\", os.getcwd())\n",
    "    imageDir = os.path.join(os.path.expanduser(\"~\"),\n",
    "                            \"data\", \"images\", \"text\", \"language-text-images\")\n",
    "print(\"Load images from\", imgDir)\n",
    "print(\"epochs:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed4055b2-e436-479f-878a-3762301322ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 images found\n",
      "data files:\n",
      "        filename category\n",
      "1652  ci2815.jpg       ci\n",
      "2573  ci0548.jpg       ci\n",
      "2769  sq3911.jpg       sq\n",
      "2155  sq4464.jpg       sq\n",
      "1343  ci2435.jpg       ci\n",
      "categories:\n",
      " ci    2028\n",
      "sq    1972\n",
      "Name: category, dtype: int64\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 17, 17, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 17, 17, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 5, 5, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 3, 3, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 3, 3, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 1, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               33280     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,560\n",
      "Trainable params: 54,344\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Prepare dataset for training model:\n",
    "# filenames = filter(lambda x: '.i' not in x, os.listdir(os.path.join(imgDir, \"train\")))\n",
    "filenames = os.listdir(os.path.join(imgDir, \"train\"))\n",
    "print(len(filenames), \"images found\")\n",
    "trainingResults = pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':pd.Series(filenames).str[:2]\n",
    "})\n",
    "print(\"data files:\")\n",
    "print(trainingResults.sample(5))\n",
    "nCategories = trainingResults.category.nunique()\n",
    "print(\"categories:\\n\", trainingResults.category.value_counts())\n",
    "## Create model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,\\\n",
    "    MaxPooling2D, AveragePooling2D,\\\n",
    "    Dropout,Flatten,Dense,Activation,\\\n",
    "    BatchNormalization\n",
    "\n",
    "# sequential (not recursive) model (one input, one output)\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,\n",
    "                 kernel_size=3,\n",
    "                 strides=2,\n",
    "                 activation='relu',\n",
    "                 kernel_initializer = initializers.HeNormal(),\n",
    "                 input_shape=(targetWidth, targetHeight, channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,\n",
    "                 kernel_size=3,\n",
    "                 kernel_initializer = initializers.HeNormal(),\n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,\n",
    "                kernel_initializer = initializers.HeNormal(),\n",
    "                activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(Dense(nCategories,\n",
    "                kernel_initializer = initializers.HeNormal(),\n",
    "                activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57715de8-7682-4950-bd12-42d8ca750599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 7s 45ms/step - loss: 0.5963 - accuracy: 0.7387\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 4s 33ms/step - loss: 0.4493 - accuracy: 0.8487\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.3884 - accuracy: 0.8717\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.3324 - accuracy: 0.8960\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.2981 - accuracy: 0.9093\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.2775 - accuracy: 0.9150\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 4s 32ms/step - loss: 0.2495 - accuracy: 0.9277\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.2494 - accuracy: 0.9233\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.2302 - accuracy: 0.9302\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.2201 - accuracy: 0.9342\n",
      "1000 validation images\n",
      "1000 validation files read from squares-circles/validation\n",
      "Found 1000 validated image filenames.\n",
      " --- Predicting on validation data ---\n",
      "32/32 [==============================] - 1s 23ms/step\n",
      "Predicted probability array shape: (1000, 2)\n",
      "Example:\n",
      " [[0.07654224 0.92345774]\n",
      " [0.9299876  0.07001241]\n",
      " [0.07650203 0.92349803]\n",
      " [0.08703131 0.91296864]\n",
      " [0.92167574 0.07832424]]\n",
      "     filename category  predicted\n",
      "0  ci0134.jpg       ci          1\n",
      "1  ci2723.jpg       ci          0\n",
      "2  ci4434.jpg       ci          1\n",
      "3  ci4346.jpg       ci          1\n",
      "4  ci1216.jpg       ci          0\n",
      "confusion matrix (validation)\n",
      "predicted   ci   sq\n",
      "category           \n",
      "ci         267  238\n",
      "sq           0  495\n",
      "Validation accuracy 0.762\n",
      "Example wrong results (validation data)\n",
      "       filename category predicted\n",
      "2    ci4434.jpg       ci        sq\n",
      "318  ci1289.jpg       ci        sq\n",
      "459  ci2396.jpg       ci        sq\n",
      "580  ci1900.jpg       ci        sq\n",
      "998  ci4377.jpg       ci        sq\n",
      "380  ci0810.jpg       ci        sq\n",
      "882  ci3426.jpg       ci        sq\n",
      "152  ci3771.jpg       ci        sq\n",
      "444  ci0350.jpg       ci        sq\n",
      "29   ci3549.jpg       ci        sq\n",
      " --- Predicting on training data: ---\n",
      "Found 4000 validated image filenames belonging to 2 classes.\n",
      "125/125 [==============================] - 2s 14ms/step\n",
      "confusion matrix (training)\n",
      "predicted    ci    sq\n",
      "category             \n",
      "ci         1069   959\n",
      "sq            2  1970\n",
      "Train accuracy 0.75975\n"
     ]
    }
   ],
   "source": [
    "## Training and validation data generator:\n",
    "trainingGenerator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ").\\\n",
    "    flow_from_dataframe(trainingResults,\n",
    "                        os.path.join(imgDir, \"train\"),\n",
    "                        x_col='filename', y_col='category',\n",
    "                        target_size=imageSize,\n",
    "                        class_mode='categorical',\n",
    "                        color_mode=\"grayscale\",\n",
    "                        shuffle=True)\n",
    "label_map = trainingGenerator.class_indices\n",
    "## Model Training:\n",
    "history = model.fit(\n",
    "    trainingGenerator,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "## Validation data preparation:\n",
    "validationDir = os.path.join(imgDir, \"validation\")\n",
    "fNames = os.listdir(validationDir)\n",
    "print(len(fNames), \"validation images\")\n",
    "validationResults = pd.DataFrame({\n",
    "    'filename': fNames,\n",
    "    'category': pd.Series(fNames).str[:2]\n",
    "})\n",
    "print(validationResults.shape[0], \"validation files read from\", validationDir)\n",
    "validationGenerator = ImageDataGenerator(rescale=1./255).\\\n",
    "    flow_from_dataframe(validationResults,\n",
    "                        os.path.join(imgDir, \"validation\"),\n",
    "                        x_col='filename',\n",
    "                        class_mode = None,\n",
    "                        target_size = imageSize,\n",
    "                        shuffle = False,\n",
    "                        # do _not_ randomize the order!\n",
    "                        # this would clash with the file name order!\n",
    "                        color_mode=\"grayscale\"\n",
    "    )\n",
    "\n",
    "## Make categorical prediction:\n",
    "print(\" --- Predicting on validation data ---\")\n",
    "phat = model.predict(validationGenerator)\n",
    "print(\"Predicted probability array shape:\", phat.shape)\n",
    "print(\"Example:\\n\", phat[:5])\n",
    "\n",
    "## Convert labels to categories:\n",
    "validationResults['predicted'] = pd.Series(np.argmax(phat, axis=-1), index=validationResults.index)\n",
    "print(validationResults.head())\n",
    "labelMap = {v: k for k, v in label_map.items()}\n",
    "validationResults[\"predicted\"] = validationResults.predicted.replace(labelMap)\n",
    "print(\"confusion matrix (validation)\")\n",
    "print(pd.crosstab(validationResults.category, validationResults.predicted))\n",
    "print(\"Validation accuracy\", np.mean(validationResults.category == validationResults.predicted))\n",
    "\n",
    "## Print and plot misclassified results\n",
    "wrongResults = validationResults[validationResults.predicted != validationResults.category]\n",
    "rows = np.random.choice(wrongResults.index, min(4, wrongResults.shape[0]), replace=False)\n",
    "print(\"Example wrong results (validation data)\")\n",
    "print(wrongResults.sample(min(10, wrongResults.shape[0])))\n",
    "if plot:\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    index = 1\n",
    "    for row in rows:\n",
    "        filename = wrongResults.loc[row, 'filename']\n",
    "        predicted = wrongResults.loc[row, 'predicted']\n",
    "        img = load_img(os.path.join(imgDir, \"validation\", filename), target_size=imageSize)\n",
    "        plt.subplot(4, 2, index)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(filename + \" ({})\".format(predicted))\n",
    "        index += 1\n",
    "    # now show correct results\n",
    "    index = 5\n",
    "    correctResults = validationResults[validationResults.predicted == validationResults.category]\n",
    "    rows = np.random.choice(correctResults.index,\n",
    "                            min(4, correctResults.shape[0]), replace=False)\n",
    "    for row in rows:\n",
    "        filename = correctResults.loc[row, 'filename']\n",
    "        predicted = correctResults.loc[row, 'predicted']\n",
    "        img = load_img(os.path.join(imgDir, \"validation\", filename), target_size=imageSize)\n",
    "        plt.subplot(4, 2, index)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(filename + \" ({})\".format(predicted))\n",
    "        index += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "## Training data predictions.\n",
    "## Do these here to keep the in place for students\n",
    "## \n",
    "print(\" --- Predicting on training data: ---\")\n",
    "# do another generator: the same as training, just w/o shuffle\n",
    "predictTrainGenerator = ImageDataGenerator(rescale=1./255).\\\n",
    "    flow_from_dataframe(trainingResults,\n",
    "                        os.path.join(imgDir, \"train\"),\n",
    "                        x_col='filename', y_col='category',\n",
    "                        target_size=imageSize,\n",
    "                        class_mode='categorical',\n",
    "                        color_mode=\"grayscale\",\n",
    "                        shuffle=False  # do not shuffle!\n",
    "    )\n",
    "phat = model.predict(predictTrainGenerator)\n",
    "trainingResults['predicted'] = pd.Series(np.argmax(phat, axis=-1), index=trainingResults.index)\n",
    "trainingResults[\"predicted\"] = trainingResults.predicted.replace(labelMap)\n",
    "print(\"confusion matrix (training)\")\n",
    "print(pd.crosstab(trainingResults.category, trainingResults.predicted))\n",
    "print(\"Train accuracy\", np.mean(trainingResults.category == trainingResults.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "02d4e6cd-c927-4599-b2a8-055d38fad6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 images found\n",
      "data files:\n",
      "        filename category\n",
      "2265  sq4277.jpg       sq\n",
      "1632  ci3504.jpg       ci\n",
      "196   sq1601.jpg       sq\n",
      "1941  ci3506.jpg       ci\n",
      "1412  ci3299.jpg       ci\n",
      "categories:\n",
      " ci    2028\n",
      "sq    1972\n",
      "Name: category, dtype: int64\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 34, 34, 16)        80        \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 34, 34, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 11, 11, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 11, 11, 16)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 9, 9, 16)          2320      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 9, 9, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 4, 4, 16)          0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 8)                 2056      \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,640\n",
      "Trainable params: 4,560\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Prepare dataset for training model:\n",
    "filenames = os.listdir(os.path.join(imgDir, \"train\"))\n",
    "print(len(filenames), \"images found\")\n",
    "trainingResults = pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':pd.Series(filenames).str[:2]\n",
    "})\n",
    "print(\"data files:\")\n",
    "print(trainingResults.sample(5))\n",
    "nCategories = trainingResults.category.nunique()\n",
    "print(\"categories:\\n\", trainingResults.category.value_counts())\n",
    "## Create model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,\\\n",
    "    MaxPooling2D, AveragePooling2D,\\\n",
    "    Dropout,Flatten,Dense,Activation,\\\n",
    "    BatchNormalization\n",
    "\n",
    "# sequential (not recursive) model (one input, one output)\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(16,\n",
    "                 kernel_size=2,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 kernel_initializer = initializers.HeNormal(),\n",
    "                 input_shape=(targetWidth, targetHeight, channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(16,\n",
    "                 kernel_size=3,\n",
    "                 kernel_initializer = initializers.HeNormal(),\n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,\n",
    "                kernel_initializer = initializers.HeNormal(),\n",
    "                activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(Dense(nCategories,\n",
    "                kernel_initializer = initializers.HeNormal(),\n",
    "                activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11da9bf5-89a4-468a-accb-c2894cf1697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Training and validation data generator:\n",
    "trainingGenerator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ").\\\n",
    "    flow_from_dataframe(trainingResults,\n",
    "                        os.path.join(imgDir, \"train\"),\n",
    "                        x_col='filename', y_col='category',\n",
    "                        target_size=imageSize,\n",
    "                        class_mode='categorical',\n",
    "                        color_mode=\"grayscale\",\n",
    "                        shuffle=True)\n",
    "label_map = trainingGenerator.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e797a8dc-6fe9-41b4-be3d-9322bed744f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 8s 46ms/step - loss: 0.5506 - accuracy: 0.7550\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 4s 32ms/step - loss: 0.4473 - accuracy: 0.8407\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 4s 33ms/step - loss: 0.3888 - accuracy: 0.8730\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.3395 - accuracy: 0.8978\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 4s 32ms/step - loss: 0.3052 - accuracy: 0.9112\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.2750 - accuracy: 0.9200\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 0.2591 - accuracy: 0.9225\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 0.2458 - accuracy: 0.9270\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.2142 - accuracy: 0.9392\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.2247 - accuracy: 0.9345\n"
     ]
    }
   ],
   "source": [
    "## Model Training:\n",
    "history = model.fit(\n",
    "    trainingGenerator,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0ccd9ca-9a00-4640-8709-71e3fdfc80f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 validation images\n",
      "1000 validation files read from squares-circles/validation\n",
      "Found 1000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "## Validation data preparation:\n",
    "validationDir = os.path.join(imgDir, \"validation\")\n",
    "fNames = os.listdir(validationDir)\n",
    "print(len(fNames), \"validation images\")\n",
    "validationResults = pd.DataFrame({\n",
    "    'filename': fNames,\n",
    "    'category': pd.Series(fNames).str[:2]\n",
    "})\n",
    "print(validationResults.shape[0], \"validation files read from\", validationDir)\n",
    "validationGenerator = ImageDataGenerator(rescale=1./255).\\\n",
    "    flow_from_dataframe(validationResults,\n",
    "                        os.path.join(imgDir, \"validation\"),\n",
    "                        x_col='filename',\n",
    "                        class_mode = None,\n",
    "                        target_size = imageSize,\n",
    "                        shuffle = False,\n",
    "                        # do _not_ randomize the order!\n",
    "                        # this would clash with the file name order!\n",
    "                        color_mode=\"grayscale\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "876cc9eb-e861-42f1-be92-1b8250917955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Predicting on validation data ---\n",
      "32/32 [==============================] - 1s 26ms/step\n",
      "Predicted probability array shape: (1000, 2)\n",
      "Example:\n",
      " [[0.19727843 0.80272156]\n",
      " [0.9231539  0.07684609]\n",
      " [0.9230086  0.07699139]\n",
      " [0.9231477  0.07685231]\n",
      " [0.92315376 0.07684622]]\n",
      "     filename category  predicted\n",
      "0  ci0134.jpg       ci          1\n",
      "1  ci2723.jpg       ci          0\n",
      "2  ci4434.jpg       ci          0\n",
      "3  ci4346.jpg       ci          0\n",
      "4  ci1216.jpg       ci          0\n",
      "confusion matrix (validation)\n",
      "predicted   ci   sq\n",
      "category           \n",
      "ci         455   50\n",
      "sq           1  494\n",
      "Validation accuracy 0.949\n",
      "Example wrong results (validation data)\n",
      "       filename category predicted\n",
      "147  ci4181.jpg       ci        sq\n",
      "492  ci1073.jpg       ci        sq\n",
      "152  ci3771.jpg       ci        sq\n",
      "380  ci0810.jpg       ci        sq\n",
      "86   ci3774.jpg       ci        sq\n",
      "345  ci4290.jpg       ci        sq\n",
      "32   ci3213.jpg       ci        sq\n",
      "0    ci0134.jpg       ci        sq\n",
      "582  ci3859.jpg       ci        sq\n",
      "238  ci2337.jpg       ci        sq\n",
      " --- Predicting on training data: ---\n",
      "Found 4000 validated image filenames belonging to 2 classes.\n",
      "125/125 [==============================] - 2s 14ms/step\n",
      "confusion matrix (training)\n",
      "predicted    ci    sq\n",
      "category             \n",
      "ci         1781   247\n",
      "sq            4  1968\n",
      "Train accuracy 0.93725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Make categorical prediction:\n",
    "print(\" --- Predicting on validation data ---\")\n",
    "phat = model.predict(validationGenerator)\n",
    "print(\"Predicted probability array shape:\", phat.shape)\n",
    "print(\"Example:\\n\", phat[:5])\n",
    "\n",
    "## Convert labels to categories:\n",
    "validationResults['predicted'] = pd.Series(np.argmax(phat, axis=-1), index=validationResults.index)\n",
    "print(validationResults.head())\n",
    "labelMap = {v: k for k, v in label_map.items()}\n",
    "validationResults[\"predicted\"] = validationResults.predicted.replace(labelMap)\n",
    "print(\"confusion matrix (validation)\")\n",
    "print(pd.crosstab(validationResults.category, validationResults.predicted))\n",
    "print(\"Validation accuracy\", np.mean(validationResults.category == validationResults.predicted))\n",
    "\n",
    "## Print and plot misclassified results\n",
    "wrongResults = validationResults[validationResults.predicted != validationResults.category]\n",
    "rows = np.random.choice(wrongResults.index, min(4, wrongResults.shape[0]), replace=False)\n",
    "print(\"Example wrong results (validation data)\")\n",
    "print(wrongResults.sample(min(10, wrongResults.shape[0])))\n",
    "if plot:\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    index = 1\n",
    "    for row in rows:\n",
    "        filename = wrongResults.loc[row, 'filename']\n",
    "        predicted = wrongResults.loc[row, 'predicted']\n",
    "        img = load_img(os.path.join(imgDir, \"validation\", filename), target_size=imageSize)\n",
    "        plt.subplot(4, 2, index)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(filename + \" ({})\".format(predicted))\n",
    "        index += 1\n",
    "    # now show correct results\n",
    "    index = 5\n",
    "    correctResults = validationResults[validationResults.predicted == validationResults.category]\n",
    "    rows = np.random.choice(correctResults.index,\n",
    "                            min(4, correctResults.shape[0]), replace=False)\n",
    "    for row in rows:\n",
    "        filename = correctResults.loc[row, 'filename']\n",
    "        predicted = correctResults.loc[row, 'predicted']\n",
    "        img = load_img(os.path.join(imgDir, \"validation\", filename), target_size=imageSize)\n",
    "        plt.subplot(4, 2, index)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(filename + \" ({})\".format(predicted))\n",
    "        index += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "## Training data predictions.\n",
    "## Do these here to keep the in place for students\n",
    "## \n",
    "print(\" --- Predicting on training data: ---\")\n",
    "# do another generator: the same as training, just w/o shuffle\n",
    "predictTrainGenerator = ImageDataGenerator(rescale=1./255).\\\n",
    "    flow_from_dataframe(trainingResults,\n",
    "                        os.path.join(imgDir, \"train\"),\n",
    "                        x_col='filename', y_col='category',\n",
    "                        target_size=imageSize,\n",
    "                        class_mode='categorical',\n",
    "                        color_mode=\"grayscale\",\n",
    "                        shuffle=False  # do not shuffle!\n",
    "    )\n",
    "phat = model.predict(predictTrainGenerator)\n",
    "trainingResults['predicted'] = pd.Series(np.argmax(phat, axis=-1), index=trainingResults.index)\n",
    "trainingResults[\"predicted\"] = trainingResults.predicted.replace(labelMap)\n",
    "print(\"confusion matrix (training)\")\n",
    "print(pd.crosstab(trainingResults.category, trainingResults.predicted))\n",
    "print(\"Train accuracy\", np.mean(trainingResults.category == trainingResults.predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
